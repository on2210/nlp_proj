{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b37d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f729573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgroup_resample(dataset, rate: float, label_key: str):\n",
    "    labels = np.array(dataset[label_key])\n",
    "\n",
    "    sampled_indices = []\n",
    "    for lbl in np.unique(labels):\n",
    "        idxs = np.where(labels == lbl)[0]\n",
    "        chosen = np.random.choice(idxs, size=int(idxs.size * rate), replace=False)\n",
    "        sampled_indices.extend(chosen.tolist())\n",
    "\n",
    "    return dataset.select(sampled_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73861d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dataset_format(dataset_arrow_path: str, label_key: str, dataset_name: str, rate: float = 0.1):\n",
    "    dataset = load_from_disk(dataset_arrow_path)\n",
    "    dataset = subgroup_resample(dataset, rate, label_key)\n",
    "    \n",
    "    tokens = dataset['tokens']\n",
    "    torch.save(tokens, f\"./{dataset_name}_tokens.pt\")\n",
    "    \n",
    "    labels = dataset[label_key]\n",
    "    processed_samples = len(dataset) * [None]\n",
    "    for i in range(len(dataset)):\n",
    "        processed_samples[i] = {\n",
    "            'subject': f'{i}'\n",
    "            , 'object': labels[i]\n",
    "        }\n",
    "\n",
    "    dataset_dict = {\n",
    "        'name': dataset_name\n",
    "        , 'prompt_templates': []\n",
    "        , 'samples': processed_samples\n",
    "    }\n",
    "    save_json = f\"./{dataset_name}.json\"\n",
    "    with open(save_json, \"w\") as f:\n",
    "        json.dump(dataset_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c6de723",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_arrow_path = r\"C:\\Users\\97254\\OneDrive\\שולחן העבודה\\Projects\\llm-context-neurons\\data\\europarl_lang\"\n",
    "label_key = 'language'\n",
    "dataset_name = 'europarl_lang'\n",
    "\n",
    "convert_dataset_format(dataset_arrow_path, label_key, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e66047fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_arrow_path = r\"C:\\Users\\97254\\OneDrive\\שולחן העבודה\\Projects\\llm-context-neurons\\data\\pile_data_source\"\n",
    "label_key = 'distribution'\n",
    "dataset_name = 'pile_data_source'\n",
    "\n",
    "convert_dataset_format(dataset_arrow_path, label_key, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d660f6c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
